{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHZswaxOW5JaKktuYkj0Xf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vruddhis/semanticshift/blob/main/csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for word bubble"
      ],
      "metadata": {
        "id": "hjNgjED2lbOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvTzyUcTNMRE",
        "outputId": "c8d52a2e-1fa2-474c-96df-9f1fac173c16",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    target_word    when    type                  date  \\\n",
            "0        bubble  before  formal  2019-12-30T07:40:23Z   \n",
            "1        bubble  before  formal  2019-12-30T07:40:23Z   \n",
            "2        bubble  before  formal  2019-12-29T10:00:35Z   \n",
            "3        bubble  before  formal  2019-12-29T10:00:00Z   \n",
            "4        bubble  before  formal  2019-12-28T15:44:27Z   \n",
            "..          ...     ...     ...                   ...   \n",
            "638      bubble   after  formal  2024-09-09T05:39:23Z   \n",
            "639      bubble   after  formal  2024-09-09T05:39:23Z   \n",
            "640      bubble   after  formal  2024-09-09T05:39:23Z   \n",
            "641      bubble   after  formal  2024-09-09T05:39:23Z   \n",
            "642      bubble   after  formal  2024-09-09T05:00:06Z   \n",
            "\n",
            "                                              sentence  \n",
            "0    The capital is a bubble into which she has esc...  \n",
            "1    The man who brings her into the bubble within ...  \n",
            "2    2 Leave the hot milk to cool As soon as the mi...  \n",
            "3    16 min: This is starting to bubble a little, a...  \n",
            "4    We thought he was a Gold Cup horse and obvious...  \n",
            "..                                                 ...  \n",
            "638  Geopolitical tensions, legal problems and conc...  \n",
            "639                             *** Is there a bubble?  \n",
            "640  In a situation where there is a bubble – and i...  \n",
            "641  “There is this worry in the air, where people ...  \n",
            "642  “We’re also committed to providing access to s...  \n",
            "\n",
            "[643 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "with open('2018-2019.json', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f)\n",
        "with open('2020-2021.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f)\n",
        "with open('2022-2024.json', 'r', encoding='utf-8') as f:\n",
        "    data3 = json.load(f)\n",
        "\n",
        "table = []\n",
        "word = \"bubble\"\n",
        "\n",
        "def find_sentences(data, time_period):\n",
        "    for article in data[\"response\"][\"results\"]:\n",
        "        text = article[\"fields\"].get(\"bodyText\", \"\")\n",
        "        date = article.get(\"webPublicationDate\", \"\")\n",
        "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "        for sentence in sentences:\n",
        "            if re.search(r\"\\bbubble\\b\", sentence, re.IGNORECASE):\n",
        "                row = {\n",
        "                    \"target_word\": word,\n",
        "                    \"when\": time_period,\n",
        "                    \"type\": \"formal\",\n",
        "                    \"date\": date,\n",
        "                    \"sentence\": sentence.strip()\n",
        "                }\n",
        "                table.append(row)\n",
        "\n",
        "find_sentences(data1, \"before\")\n",
        "find_sentences(data2, \"during\")\n",
        "find_sentences(data3, \"after\")\n",
        "\n",
        "df = pd.DataFrame(table, columns=[\"target_word\", \"when\", \"type\", \"date\", \"sentence\"])\n",
        "print(df)\n",
        "df.to_csv(\"bubbleCSV.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for word model"
      ],
      "metadata": {
        "id": "Cx_60b4jlWxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "with open('beforemodel.jsonl', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f)\n",
        "\n",
        "with open('aftermodel.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f)\n",
        "\n",
        "table = []\n",
        "word = \"model\"\n",
        "\n",
        "def find_sentences(data, time_period, is_jsonl=False):\n",
        "    if isinstance(data, list):\n",
        "        articles = data\n",
        "    else:\n",
        "        articles = data.get(\"response\", {}).get(\"results\", [])\n",
        "    for article in articles:\n",
        "        text = article.get(\"fields\", {}).get(\"bodyText\", \"\")\n",
        "        date = article.get(\"webPublicationDate\", \"\")\n",
        "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "        for sentence in sentences:\n",
        "            if re.search(r\"\\bmodel\\b\", sentence, re.IGNORECASE):\n",
        "                row = {\n",
        "                    \"target_word\": word,\n",
        "                    \"when\": time_period,\n",
        "                    \"type\": \"formal\",\n",
        "                    \"date\": date,\n",
        "                    \"sentence\": sentence.strip()\n",
        "                }\n",
        "                table.append(row)\n",
        "\n",
        "find_sentences(data1, \"before\")\n",
        "find_sentences(data2, \"after\")\n",
        "\n",
        "df = pd.DataFrame(table, columns=[\"target_word\", \"when\", \"type\", \"date\", \"sentence\"])\n",
        "df.to_csv(\"modelCSV.csv\", index=False)"
      ],
      "metadata": {
        "id": "G-Vd-5GsiCuC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for word prompt"
      ],
      "metadata": {
        "id": "77hI9FRilhPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "with open('beforePrompt.json', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f)\n",
        "\n",
        "with open('afterPrompt.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f)\n",
        "\n",
        "table = []\n",
        "word = \"prompt\"\n",
        "\n",
        "def find_sentences(data, time_period, is_jsonl=False):\n",
        "    if isinstance(data, list):\n",
        "        articles = data\n",
        "    else:\n",
        "        articles = data.get(\"response\", {}).get(\"results\", [])\n",
        "    for article in articles:\n",
        "        text = article.get(\"fields\", {}).get(\"bodyText\", \"\")\n",
        "        date = article.get(\"webPublicationDate\", \"\")\n",
        "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "        for sentence in sentences:\n",
        "            if re.search(r\"\\bprompt\\b\", sentence, re.IGNORECASE):\n",
        "                row = {\n",
        "                    \"target_word\": word,\n",
        "                    \"when\": time_period,\n",
        "                    \"type\": \"formal\",\n",
        "                    \"date\": date,\n",
        "                    \"sentence\": sentence.strip()\n",
        "                }\n",
        "                table.append(row)\n",
        "\n",
        "find_sentences(data1, \"before\")\n",
        "find_sentences(data2, \"after\")\n",
        "\n",
        "df = pd.DataFrame(table, columns=[\"target_word\", \"when\", \"type\", \"date\", \"sentence\"])\n",
        "df.to_csv(\"promptCSV.csv\", index=False)"
      ],
      "metadata": {
        "id": "L9Yj-vrakOZZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for word remote"
      ],
      "metadata": {
        "id": "hmwTcHstyZ38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "with open('2018-2019remote.json', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f)\n",
        "\n",
        "with open('2020-2021remote.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f)\n",
        "\n",
        "with open('2023-2024remote.json', 'r', encoding='utf-8') as f:\n",
        "    data3 = json.load(f)\n",
        "\n",
        "table = []\n",
        "word = \"remote\"\n",
        "\n",
        "def find_sentences(data, time_period, is_jsonl=False):\n",
        "    if isinstance(data, list):\n",
        "        articles = data\n",
        "    else:\n",
        "        articles = data.get(\"response\", {}).get(\"results\", [])\n",
        "    for article in articles:\n",
        "        text = article.get(\"fields\", {}).get(\"bodyText\", \"\")\n",
        "        date = article.get(\"webPublicationDate\", \"\")\n",
        "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "        for sentence in sentences:\n",
        "            if re.search(r\"\\bprompt\\b\", sentence, re.IGNORECASE):\n",
        "                row = {\n",
        "                    \"target_word\": word,\n",
        "                    \"when\": time_period,\n",
        "                    \"type\": \"formal\",\n",
        "                    \"date\": date,\n",
        "                    \"sentence\": sentence.strip()\n",
        "                }\n",
        "                table.append(row)\n",
        "\n",
        "find_sentences(data1, \"before\")\n",
        "find_sentences(data2, \"after\")\n",
        "\n",
        "df = pd.DataFrame(table, columns=[\"target_word\", \"when\", \"type\", \"date\", \"sentence\"])\n",
        "df.to_csv(\"remoteCSV.csv\", index=False)"
      ],
      "metadata": {
        "id": "2uw6vfRJy0gv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for word algorithm"
      ],
      "metadata": {
        "id": "ZU5xsw-q51ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "with open('2015-2018algo.json', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f)\n",
        "\n",
        "with open('2019-2020algo.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f)\n",
        "\n",
        "with open('2021-2025algo.json', 'r', encoding='utf-8') as f:\n",
        "    data3 = json.load(f)\n",
        "\n",
        "table = []\n",
        "word = \"algorithm\"\n",
        "\n",
        "def find_sentences(data, time_period, is_jsonl=False):\n",
        "    if isinstance(data, list):\n",
        "        articles = data\n",
        "    else:\n",
        "        articles = data.get(\"response\", {}).get(\"results\", [])\n",
        "    for article in articles:\n",
        "        text = article.get(\"fields\", {}).get(\"bodyText\", \"\")\n",
        "        date = article.get(\"webPublicationDate\", \"\")\n",
        "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "        for sentence in sentences:\n",
        "            if re.search(r\"\\bprompt\\b\", sentence, re.IGNORECASE):\n",
        "                row = {\n",
        "                    \"target_word\": word,\n",
        "                    \"when\": time_period,\n",
        "                    \"type\": \"formal\",\n",
        "                    \"date\": date,\n",
        "                    \"sentence\": sentence.strip()\n",
        "                }\n",
        "                table.append(row)\n",
        "\n",
        "find_sentences(data1, \"before\")\n",
        "find_sentences(data2, \"after\")\n",
        "\n",
        "df = pd.DataFrame(table, columns=[\"target_word\", \"when\", \"type\", \"date\", \"sentence\"])\n",
        "df.to_csv(\"algorithmCSV.csv\", index=False)"
      ],
      "metadata": {
        "id": "kcL_ju_v54ET"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}